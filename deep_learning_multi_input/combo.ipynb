{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/flipkart_com-ecommerce_sample_1050.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['categorie'] = [c[2:-1].split('>>')[0][0:-1].lower().replace(\" \",\"_\") for c in df[\"product_category_tree\"]]\n",
    "df = df[['categorie','description','image']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categorie</th>\n",
       "      <th>description</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>home_furnishing</td>\n",
       "      <td>Key Features of Elegance Polyester Multicolor ...</td>\n",
       "      <td>55b85ea15a1536d46b7190ad6fff8ce7.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baby_care</td>\n",
       "      <td>Specifications of Sathiyas Cotton Bath Towel (...</td>\n",
       "      <td>7b72c92c2f6c40268628ec5f14c6d590.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baby_care</td>\n",
       "      <td>Key Features of Eurospa Cotton Terry Face Towe...</td>\n",
       "      <td>64d5d4a258243731dc7bbb1eef49ad74.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>home_furnishing</td>\n",
       "      <td>Key Features of SANTOSH ROYAL FASHION Cotton P...</td>\n",
       "      <td>d4684dcdc759dd9cdf41504698d737d8.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>home_furnishing</td>\n",
       "      <td>Key Features of Jaipur Print Cotton Floral Kin...</td>\n",
       "      <td>6325b6870c54cd47be6ebfbffa620ec7.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         categorie                                        description  \\\n",
       "0  home_furnishing  Key Features of Elegance Polyester Multicolor ...   \n",
       "1        baby_care  Specifications of Sathiyas Cotton Bath Towel (...   \n",
       "2        baby_care  Key Features of Eurospa Cotton Terry Face Towe...   \n",
       "3  home_furnishing  Key Features of SANTOSH ROYAL FASHION Cotton P...   \n",
       "4  home_furnishing  Key Features of Jaipur Print Cotton Floral Kin...   \n",
       "\n",
       "                                  image  \n",
       "0  55b85ea15a1536d46b7190ad6fff8ce7.jpg  \n",
       "1  7b72c92c2f6c40268628ec5f14c6d590.jpg  \n",
       "2  64d5d4a258243731dc7bbb1eef49ad74.jpg  \n",
       "3  d4684dcdc759dd9cdf41504698d737d8.jpg  \n",
       "4  6325b6870c54cd47be6ebfbffa620ec7.jpg  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_in = layers.Input(shape=(len_voc,),name=\"nlp_in\")\n",
    "nlp_1 = layers.Dense(64,activation='relu',name=\"nlp_1\")(nlp_in)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_in = layers.Input(shape=(128,128,3),name=\"cv_in\")\n",
    "cv_1 = layers.Conv2D(32, (3, 3), activation='relu',input_shape=(128, 128, 3),name=\"cv_1\")(cv_in)\n",
    "cv_2 = layers.MaxPooling2D((2,2),name=\"cv_2\")(cv_1)\n",
    "cv_3 = layers.Conv2D(64, (3, 3), activation='relu',name=\"cv_3\")(cv_2)\n",
    "cv_4 = layers.MaxPooling2D((2,2),name=\"cv_4\")(cv_3)\n",
    "cv_5 = layers.Conv2D(64, (3, 3), activation='relu',name=\"cv_5\")(cv_4)\n",
    "cv_6 = layers.Flatten(name=\"cv_6\")(cv_5)\n",
    "cv_7 = layers.Dropout(0.2,name=\"cv_7\")(cv_6)\n",
    "cv_8 = layers.Dense(64,activation='relu',name=\"cv_8\")(cv_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging model nlp and cv\n",
    "fusion = layers.concatenate([nlp_1,cv_8],name=\"fusion_layer\")\n",
    "#Final Layer\n",
    "output_layer = layers.Dense(7, activation = \"softmax\", name = \"output_layer\")(fusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "X_cv= []\n",
    "for i in df[\"image\"]:\n",
    "    im = image = cv2.imread(\"data/Images_reshape/\"+i)\n",
    "    X_cv.append(im)\n",
    "X_cv = np.array(X_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#df[\"image_file\"] = X_cv\n",
    "X = df['description']\n",
    "y=df['categorie']\n",
    "X_2, X_test, y_2, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_2, y_2, test_size=0.15, random_state=42)\n",
    "\n",
    "X_2, X_test_cv, y_2, y_test = train_test_split(X_cv, y, test_size=0.15, random_state=42)\n",
    "X_train_cv, X_val_cv, y_train, y_val = train_test_split(X_2, y_2, test_size=0.15, random_state=42)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X)\n",
    "X_train_vect = vectorizer.transform(X_train)\n",
    "X_test_vect = vectorizer.transform(X_test)\n",
    "X_val_vect = vectorizer.transform(X_val)\n",
    "len_voc = len(vectorizer.vocabulary_)\n",
    "\n",
    "# je dois trasnformer ma variable cible en dummies \n",
    "# afin que chaque neurone de la derni√®re couche ait sa propre colone.\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "#y_train.replace([\"happy\",\"sadness\",\"anger\",\"fear\",\"love\",\"surprise\"],[0,1,2,3,4,5],inplace=True)\n",
    "#y_test.replace([\"happy\",\"sadness\",\"anger\",\"fear\",\"love\",\"surprise\"],[0,1,2,3,4,5],inplace=True)\n",
    "y_train.replace([\"beauty_and_personal_care\",\"kitchen_&_dining\",\"baby_care\",\"home_decor_&_festive_needs\",\"watches\",\"home_furnishing\",\"computers\"],[0,1,2,3,4,5,6],inplace=True)\n",
    "y_test.replace([\"beauty_and_personal_care\",\"kitchen_&_dining\",\"baby_care\",\"home_decor_&_festive_needs\",\"watches\",\"home_furnishing\",\"computers\"],[0,1,2,3,4,5,6],inplace=True)\n",
    "y_val.replace([\"beauty_and_personal_care\",\"kitchen_&_dining\",\"baby_care\",\"home_decor_&_festive_needs\",\"watches\",\"home_furnishing\",\"computers\"],[0,1,2,3,4,5,6],inplace=True)\n",
    "\n",
    "dummy_y_train = to_categorical( y_train)\n",
    "dummy_y_test = to_categorical( y_test)\n",
    "dummy_y_val = to_categorical( y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"merged_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "cv_in (InputLayer)              [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cv_1 (Conv2D)                   (None, 126, 126, 32) 896         cv_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "cv_2 (MaxPooling2D)             (None, 63, 63, 32)   0           cv_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "cv_3 (Conv2D)                   (None, 61, 61, 64)   18496       cv_2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "cv_4 (MaxPooling2D)             (None, 30, 30, 64)   0           cv_3[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "cv_5 (Conv2D)                   (None, 28, 28, 64)   36928       cv_4[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "cv_6 (Flatten)                  (None, 50176)        0           cv_5[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "nlp_in (InputLayer)             [(None, 6053)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cv_7 (Dropout)                  (None, 50176)        0           cv_6[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "nlp_1 (Dense)                   (None, 64)           387456      nlp_in[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "cv_8 (Dense)                    (None, 64)           3211328     cv_7[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "fusion_layer (Concatenate)      (None, 128)          0           nlp_1[0][0]                      \n",
      "                                                                 cv_8[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 7)            903         fusion_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 3,656,007\n",
      "Trainable params: 3,656,007\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "#Model Definition \n",
    "merged = Model(inputs=[(nlp_in,cv_in)],outputs=[output_layer], name = \"merged_model\")\n",
    "#Model Details\n",
    "merged.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24/24 [==============================] - 9s 361ms/step - loss: 44.5182 - accuracy: 0.3417 - val_loss: 1.4057 - val_accuracy: 0.6045\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 8s 346ms/step - loss: 0.8665 - accuracy: 0.8298 - val_loss: 0.9071 - val_accuracy: 0.8209\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 8s 346ms/step - loss: 0.3758 - accuracy: 0.9551 - val_loss: 0.7026 - val_accuracy: 0.8134\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 8s 346ms/step - loss: 0.2520 - accuracy: 0.9670 - val_loss: 0.7710 - val_accuracy: 0.7910\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 10s 409ms/step - loss: 0.1609 - accuracy: 0.9776 - val_loss: 0.6189 - val_accuracy: 0.8582\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 10s 402ms/step - loss: 0.1065 - accuracy: 0.9894 - val_loss: 0.8154 - val_accuracy: 0.8134\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 8s 346ms/step - loss: 0.0560 - accuracy: 0.9934 - val_loss: 0.7923 - val_accuracy: 0.7836\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 7s 295ms/step - loss: 0.0362 - accuracy: 0.9987 - val_loss: 0.8905 - val_accuracy: 0.7836\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 7s 289ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.8436 - val_accuracy: 0.7836\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 7s 290ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 1.2418 - val_accuracy: 0.7313\n"
     ]
    }
   ],
   "source": [
    "merged.compile(optimizer='adam', \n",
    "             loss=\"CategoricalCrossentropy\",\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "history = merged.fit([X_train_vect, X_train_cv], dummy_y_train, epochs=10, \n",
    "                    validation_data=([X_val_vect, X_val_cv], dummy_y_val),batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 66ms/step - loss: 1.4065 - accuracy: 0.7468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4065269231796265, 0.746835470199585]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.evaluate([X_test_vect,X_test_cv],dummy_y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "27e8c10dbf50e39a9ac51383911f9d7044c43e11a13d12e60f343ebdd366d09d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.15 ('pyton38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
